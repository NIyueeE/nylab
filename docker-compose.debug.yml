# docker-compose.debug.yml
version: '3.7'

services:
  # MinIO 对象存储（调试版）
  minio:
    image: minio/minio
    container_name: minio_debug
    ports:
      - "9000:9000"
      - "9001:9001"
    command: server /data --console-address ':9001'
    environment:
      MINIO_ROOT_USER: ${AWS_ACCESS_KEY_ID}
      MINIO_ROOT_PASSWORD: ${AWS_SECRET_ACCESS_KEY}
    volumes:
      - minio_data:/data
    healthcheck:
      test: ["CMD", "curl", "-f", "http://localhost:9000/minio/health/live"]
      interval: 10s
      timeout: 5s
      retries: 3
  
  mc:
    image: minio/mc
    container_name: mc_debug
    env_file:
      - .env
    entrypoint: |
      /bin/sh -c "
      /tmp/wait-for-it.sh minio:9000 &&
      /usr/bin/mc alias set minio http://minio:9000 $${AWS_ACCESS_KEY_ID} $${AWS_SECRET_ACCESS_KEY} &&
      (/usr/bin/mc ls minio/mlflow || /usr/bin/mc mb minio/mlflow) &&
      (/usr/bin/mc ls minio/mlflow-datasets || /usr/bin/mc mb minio/mlflow-datasets);
      exit 0;
      "
    volumes:
      - ./wait-for-it.sh:/tmp/wait-for-it.sh
    depends_on:
      minio:
        condition: service_healthy

  # MLflow 跟踪服务器（调试版）
  mlflow:
    build: ./mlflow
    image: mlflow_server
    container_name: nylab_mlflow_debug
    ports:
      - "5000:5000"
    environment:
      MLFLOW_S3_ENDPOINT_URL: http://minio:9000
      AWS_ACCESS_KEY_ID: ${AWS_ACCESS_KEY_ID}
      AWS_SECRET_ACCESS_KEY: ${AWS_SECRET_ACCESS_KEY}
    command: >
      sh -c "
      mlflow server
      --backend-store-uri sqlite:///mlflow.db
      --default-artifact-root s3://mlflow/
      --host 0.0.0.0

      while ! mc ls minio/mlflow >/dev/null 2>&1; do sleep 1; done;
      "
    depends_on:
      minio:
        condition: service_healthy
      mc:
        condition: service_completed_successfully

  # Redis 服务（调试版）
  redis:
    image: redis:alpine
    container_name: nylab_redis_debug
    ports:
      - "6379:6379"
    healthcheck:
      test: ["CMD", "redis-cli", "ping"]
      interval: 5s
      timeout: 3s
      retries: 3

  # 后端API服务（调试模式）
  backend:
    build:
      context: ./backend
      dockerfile: Dockerfile
    container_name: nylab_backend_debug
    ports:
      - "8000:8000"   # API端口
      - "5678:5678"   # 调试端口
    volumes:
      - ./backend:/app  # 代码热重载
      - shared_data:/data
    environment:
      PYTHONUNBUFFERED: "1"
      MLFLOW_TRACKING_URI: http://mlflow:5000
      MINIO_ENDPOINT: minio:9000
      AWS_ACCESS_KEY_ID: ${AWS_ACCESS_KEY_ID}
      AWS_SECRET_ACCESS_KEY: ${AWS_SECRET_ACCESS_KEY}
      REDIS_HOST: redis
      CELERY_BROKER_URL: redis://redis:6379/0
    command: >
      sh -c "pip install debugpy -q &&
             python -m debugpy --listen 0.0.0.0:5678 --wait-for-client -m uvicorn app.main:app --host 0.0.0.0 --port 8000 --reload"
    depends_on:
      redis:
        condition: service_healthy
      mlflow:
        condition: service_started

  # Celery Worker（调试模式）
  celery-worker:
    build:
      context: ./backend
      dockerfile: Dockerfile
    container_name: nylab_celery_worker_debug
    volumes:
      - shared_data:/data
      - ./backend:/app  # 代码热重载

    environment:
      MLFLOW_TRACKING_URI: http://mlflow:5000
      MINIO_ENDPOINT: minio:9000
      AWS_ACCESS_KEY_ID: ${AWS_ACCESS_KEY_ID}
      AWS_SECRET_ACCESS_KEY: ${AWS_SECRET_ACCESS_KEY}
      REDIS_HOST: redis
      CELERY_BROKER_URL: redis://redis:6379/0
    command: >
      sh -c "pip install watchdog -q &&
             watchmedo auto-restart --directory=/app --pattern='*.py' --recursive -- 
             celery -A app.tasks.celery_app worker --loglevel=info --concurrency=1"
    depends_on:
      redis:
        condition: service_healthy
      backend:
        condition: service_started

volumes:
  minio_data:
  shared_data: